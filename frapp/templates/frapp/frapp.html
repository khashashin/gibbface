{% extends "base.html" %}
{% load static %}

{% load wagtailcore_tags %}

{% block body_class %}template-frapp{% endblock %}

{% block content %}

    {% block go_to_top_button %}
    {% endblock %}

    <h1>frapp</h1>
    <div style="position: relative" class="margin">
        <video onloadedmetadata="onPlay(this)" id="video" autoplay muted playsinline width="480" height="384" style="
            position: absolute;
            z-index: -1;
            top: 0;
            left: 0;
        "></video>
        <canvas id="overlay" width="480" height="384" style="
            width: 480px;
            height: 384px;
            position: absolute;
            z-index: 1;
            left: 0;
            top: 0;
        "></canvas>
    </div>
    <div id="fps_meter" class="row side-by-side" style="
    bottom: 0;
    position: absolute;
    left: 30px;
">
        <div>
            <label for="time">Time:</label>
            <input disabled value="-" id="time" type="text" class="bold">
            <label for="fps">Estimated Fps:</label>
            <input disabled value="-" id="fps" type="text" class="bold">
        </div>
    </div>

{% endblock %}

{% block extra_js %}
    <script src="{% static 'js/face-api.min.js' %}"></script>
    <script src="{% static 'js/adapter.js' %}"></script>
    <script>
        let video;
        let canvas;
        let stream;
        let forwardTimes = [];
        const minConfidence = 0.6;
        const maxResults = 1;
        $(document).ready(function () {
            video = $('#video').get(0);
            canvas = $('#overlay').get(0);
            canvas.width = 480;
            canvas.height = 384;
            run();
        });

        function updateTimeStats(timeInMs) {
            forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30);
            const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length;
            $('#time').val(`${Math.round(avgTimeInMs)} ms`);
            $('#fps').val(`${faceapi.round(1000 / avgTimeInMs)}`);
        }

        async function run() {
            // load the models
            await faceapi.loadMtcnnModel(`{% static 'models/mtcnn/mtcnn_model-weights_manifest.json' %}`);
            await faceapi.loadFaceRecognitionModel(`{% static 'models/fr/face_recognition_model-weights_manifest.json' %}`);
            await faceapi.loadTinyFaceDetectorModel(`{% static 'models/fd/tiny_face_detector_model-weights_manifest.json' %}`);
            navigator.mediaDevices.getUserMedia({audio: false, video: true}).then(stream => {
                video.srcObject = stream;
                video.play();
            }).catch(e => console.warn(e));
        }

        async function onPlay() {
            if (video.paused || video.ended)
                return setTimeout(() => onPlay());

            // tiny_face_detector options
            let inputSize = 384;
            let scoreThreshold = 0.5;
            const options = new faceapi.TinyFaceDetectorOptions({inputSize, scoreThreshold});

            const ts = Date.now();

            const result = await faceapi.detectSingleFace(video, options);

            updateTimeStats(Date.now() - ts);

            if (result) {
                const dims = faceapi.matchDimensions(canvas, video, true);
                faceapi.draw.drawDetections(canvas, faceapi.resizeResults(result, dims))
            }

            setTimeout(() => onPlay())
        }
    </script>
{% endblock %}